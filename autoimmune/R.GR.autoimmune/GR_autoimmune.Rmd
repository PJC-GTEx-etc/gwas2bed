---
title: "Genetic and epigenetic fine mapping of causal autoimmune disease variants"
author: "Mikhail Dozmorov"
date: "November 1, 2014"
output: html_document
---
```{r setup, echo=FALSE, message=FALSE}
source("utils.R")
suppressMessages(library(Hmisc)) # For rcorr function
suppressMessages(library(gplots))
suppressMessages(library(Biobase))
suppressMessages(library(limma))
suppressMessages(library(reshape2))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
#library(qvalue)
# Set up the environment
library(knitr) 
opts_chunk$set(cache.path='cache/', fig.path='img/', cache=F, tidy=T, fig.keep='high', echo=F, dpi=300, out.width=700)
options(replace.assign=TRUE, width=120)
suppressMessages(library(pander))
panderOptions('table.split.table', Inf)
set.seed(1)
```

```{r loadSharedData}
# All disease-disease relationships
mtx.disease <- read.table("../../AllNet3.net", sep="\t", header=F)
# Mapping of term IDs to ICD9 codes
term.mapping <- read.table("data/icd9_mapping.txt", sep="\t", header=F)
colnames(term.mapping) <- c("term", "ICD9", "iridescent")
# Sanity check, is there differences in disease codes? Should be 0
# setdiff(unique(term.mapping$ICD9), unique(mtx.disease$V1))
```

We analyzed 39 autoimmune disease- and trait-associated SNP sets, obtained from the [Supplemental table 1](http://www.nature.com/nature/journal/vaop/ncurrent/extref/nature13835-s1.xls) of the Farh, K. K.-H., Marson, A., Zhu, J., Kleinewietfeld, M., Housley, W. J., Beik, S., â€¦ Bernstein, B. E. (2014). ["Genetic and epigenetic fine mapping of causal autoimmune disease variants""](http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature13835.pdf) Nature. [doi:10.1038/nature13835](doi:10.1038/nature13835).

First, we re-created the heatmap of shared genetic features among the autoimmune diseases and traits, that is, counts of genomic elements overlapping between pairs of terms. We will use this heatmap as a reference point to compare with the heatmaps produced by the regulatory similarity analysis.

```{r loadOverlapMtx_own, warning=FALSE, message=FALSE, fig.height=6, eval=FALSE}
# Self-prepared overlap analysis
mtx.overlap <- read.table("data/overlapMatrix.txt", sep="\t", head=F)
mtx.overlap.carpet <- dcast(mtx.overlap, V1~V2, mean)
rownames(mtx.overlap.carpet) <- mtx.overlap.carpet$V1
mtx.overlap.carpet <- as.matrix(mtx.overlap.carpet[, -1])
mtx.overlap$V1 <- sub(".bed", "", mtx.overlap$V1)
mtx.overlap$V2 <- sub(".bed", "", mtx.overlap$V2)
```

```{r visualizeOverlapMtx_own, eval=FALSE}
# We visualize clustering of disease-specific SNP sets based on the number of overlapping SNPs.
par(oma=c(5,0,0,5), mar=c(10, 4.1, 4.1, 5)) # Adjust margins
color<-colorRampPalette(c("blue","yellow")) # Define color gradient
#color<-greenred #Standard green-black-red palette
# Adjust clustering parameters.
# Distance: "euclidean", "maximum","manhattan" or "minkowski". Do not use "canberra" or "binary"
# Clustering: "ward", "single", "complete", "average", "mcquitty", "median" or "centroid"
dist.method<-"euclidean"  
hclust.method<-"ward.D2"
# Setting breaks to go from minimum to maximum correlation coefficients,
# excluding min/max outliers. This way we get rid of diagonale of 1's
h<-heatmap.2(mtx.overlap.carpet, trace="none", density.info="none", col=color, distfun=function(x){dist(x, method=dist.method)}, hclustfun=function(x){hclust(x, method=hclust.method)}, cexRow=0.7, cexCol=0.7, scale="row")
```

```{r visualizeOverlapMtx_original, warning=FALSE, message=FALSE, fig.height=12}
mtx.fig1a <- read.table("data/fig1a_matrix", sep="\t", header=F, stringsAsFactors=F)
a <- as.matrix(mtx.fig1a) # For heatmap
labels.fig1a <- readLines("data/fig1a_labels")
colnames(mtx.fig1a) <- labels.fig1a; mtx.fig1a <- cbind(labels.fig1a, mtx.fig1a)
mtx.fig1a.melt <- melt(mtx.fig1a)
colnames(mtx.fig1a.melt) <- c("term1", "term2", "overlap")
# Plotting
colnames(a) <- labels.fig1a; rownames(a) <- labels.fig1a
heatmap.2(a, trace="none", density.info="none", col=color, scale="none", cexRow=0.7, cexCol=0.7)
```

Analysis of all regulatory datasets
===
Although we used 4,498 regulatory datasets from the ENCODE project processed with the use with GenomeRunner, some regulatory datasets show not statistically significant enrichments in any of the 39 SNP sets. We removed these datasets as non-informative, and kept the remaining 2,969 regulatory datasets.

```{r loadData3, echo=FALSE}
# Define output and data subfolders to use, change to analyze different data
rname<-"results//" # Output folder
# One or more GenomeRunner Web results data folders.
dname <- "data.gr//ENCODE_FDR/"
mtx<-do.call("rbind", lapply(dname, function(fn) as.matrix(read.table(paste(fn, "matrix.txt", sep=""), sep="\t", header=T, row.names=1))))
# mtx <- mtx[grep("histone", rownames(mtx), ignore.case=T), ] # Limit the GFs to TFBSs and Histone marks
# Exploratory: check quantiles and remove diseaases showing no enrichments
# mtx.sumstat <- as.data.frame(apply(mtx, 2, quantile)) # Get quantiles
# mtx <- mtx[ , apply(mtx.sumstat, 2, function(x) sum(abs(x)) != 5)] # REmove those that have all "1" or "-1"
# Optional: filter unused genomic features
# mtx<-mtx[grep("snp", rownames(mtx), ignore.case=T, invert=T), ]
mtx<-mtx.transform(mtx) # -log10 transform p-values
# Optional: adjust columns for multiple testing. See utils.R for the function definition.
# mtx<-mtx.adjust(mtx) 
trackDb.hg19 <- read.table("data.gr//gf_descriptions.hg19.txt", sep="\t", row.names=1)
fn_maxmin <- "results//maxmin_correlations_all.txt"
fn_clust <- "results/clustering_all.txt"
fn_degs <- "results/clusters-degs_all.txt"
```

```{r preprocessData3, echo=FALSE}
dim(mtx) # Check original dimensions
# Define minimum number of times a row/col should have values above the cutoffs
numofsig<-1
cutoff<- -log10(0.1) # q-value significance cutoff
# What remains if we remove rows/cols with nothing significant
dim(mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ])
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig])
# Trim the matrix
mtx<-mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ]
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig]
```

```{r preprocessCorrel3, echo=FALSE}
# rcorr returns a list, [[1]] - correl coeffs, [[3]] - p-values. Type - pearson/spearman
mtx.cor<-rcorr(as.matrix(mtx), type="spearman")
# Optionally, try kendall correlation
# mtx.cor[[1]]<-cor(as.matrix(mtx), method="kendall")
```

We visualized the matrix of pair-wise Spearman correlation coefficients among the term-specific regulatory enrichment profiles.

```{r epigenomicVisualization3, echo=FALSE, fig.height=}
par(oma=c(5,0,0,5), mar=c(10, 4.1, 4.1, 5)) # Adjust margins
color<-colorRampPalette(c("blue","yellow")) # Define color gradient
#color<-greenred #Standard green-black-red palette
# Adjust clustering parameters.
# Distance: "euclidean", "maximum","manhattan" or "minkowski". Do not use "canberra" or "binary"
# Clustering: "ward", "single", "complete", "average", "mcquitty", "median" or "centroid"
dist.method<-"euclidean"  
hclust.method<-"ward.D2"
# Setting breaks to go from minimum to maximum correlation coefficients,
# excluding min/max outliers. This way we get rid of diagonale of 1's
granularity = 10
my.breaks <- seq(min(mtx.cor[[1]][mtx.cor[[1]]!=min(mtx.cor[[1]])]),
                 max(mtx.cor[[1]][mtx.cor[[1]]!=max(mtx.cor[[1]])]),
                 length.out=(2*granularity + 1))
h<-heatmap.2(as.matrix(mtx.cor[[1]]), trace="none", density.info="none", col=color, distfun=function(x){dist(x, method=dist.method)}, hclustfun=function(x){hclust(x, method=hclust.method)}, cexRow=0.7, cexCol=0.7, breaks=my.breaks)
```

We then compared how regulatory similarity correlates with shared genomic features similarity. Spearman correlation coefficient between the two is:

```{r RegOverlapCorrel3_own, eval=FALSE}
# Using self-made overlap matrix
mtx.cor.melt <- melt(mtx.cor[[1]]) # Convert correlation matrix to long format
c <- left_join(mtx.overlap, mtx.cor.melt, by = c("V1" = "Var1", "V2" = "Var2"))
(rcorr(c[, 3], c[, 4], type="spearman")[[1]][1, 2]) # Finally, correlation between the two
```

```{r RegOverlapCorrel3_original}
# Using authors-provided overlap matrix
mtx.cor.melt <- melt(mtx.cor[[1]]) # Convert correlation matrix to long format
c <- left_join(mtx.fig1a.melt, mtx.cor.melt, by=c("term1" = "Var1", "term2" = "Var2"))
(rcorr(c[, 3], c[, 4], type="spearman")[[1]][1, 2]) # Finally, correlation between the two
```

The top 10 pairs of disease- aassociated SNPs are most similar with each other. The correlation coefficient shows Spearman correlation coefficient among the regulatory enrichment profiles for each term-specific SNP set.

```{r maxMin3, echo=FALSE}
# Checking max/min correlations
mtx.cor1<-mtx.cor[[1]]
diag(mtx.cor1)<-0 # We don't need to consider self correlations, zero them out
mtx.cor1[lower.tri(mtx.cor1)] <- 0 # Also zero out one matrix triangle, to avoid duplicate pairs
mtx.maxMin <- melt(mtx.cor1) # Convert the matrix into tidy data
mtx.maxMin <- mtx.maxMin[order(mtx.maxMin$value, decreasing=T), ] # Reorder the data by maxMin correlation
mtx.maxMin <- mtx.maxMin[mtx.maxMin$value != 0, ]
row.names(mtx.maxMin) <- NULL
colnames(mtx.maxMin) <- c("Disease 1", "Disease 2", "Corr. coefficient")
pander(head(mtx.maxMin, n=10))
write.table(mtx.maxMin, fn_maxmin, sep="\t", quote=F,  row.names=F)
mtx.maxMin.all <- data.frame(coef=mtx.maxMin[, 3]) # Save the data for future plotting
mtx.maxMin.all$type <- "all" # Label it
```

The regulatory similarity dendrogram can be divided into four separate clusters:

```{r defineClusters3, echo=FALSE}
par(oma=c(0, 0, 0, 0), mar=c(5.1, 4.1, 4.1,25.1), cex=0.5)
# Plot the dendrogram only, limit y axis. attr(h$colDendrogram, "height") has the maximum height of the dendrogram.
plot(h$colDendrogram, horiz=T) 
# Cut the dentrogram into separate clusters. Tweak the height
abline(v=2.55) # Visually evaluate the height where to cut
c<-cut(h$colDendrogram, h=2.55) 
# Check the number of clusters, and the number of members.
for (i in 1:length(c$lower)){
  cat(paste("Cluster", formatC(i, width=2, flag="0"), sep=""), "has", formatC(attr(c$lower[[i]], "members"), width=3), "members", "\n")
  cat(paste(t(labels(c$lower[[i]])), collapse="\n"))
  cat(paste("\n", "\n"))
}
# Output the results into a file
unlink(fn_clust)
for (i in 1:length(c$lower)){ 
  write.table(paste(i, t(labels(c$lower[[i]])), sep="\t"), fn_clust, sep="\t", quote=F,  col.names=F, row.names=F, append=T)
}
```

```{r defineGroups3, echo=FALSE}
eset.labels<-character() # Empty vector to hold cluster labels
eset.groups<-numeric() # Empty vector to hold cluster groups
# Set the minimum number of members to be considered for the differential analysis
minmembers<-3
for (i in 1:length(c$lower)) { # Go through each cluster
  # If the number of members is more than a minimum number of members
  if (attr(c$lower[[i]], "members") > minmembers) { 
    eset.labels<-append(eset.labels, labels(c$lower[[i]]))
    eset.groups<-append(eset.groups, rep(i, length(labels(c$lower[[i]]))))
  }
}
```

We estimated the differences in regulatory associations of term-secific SNP sets.  

The first column shows names of regulatory datasets. The following two columns show the average p-values of the cluster-specific SNP sets-regulatory associations. The smaller a p-value is, the more SNPs in a cluster enriched in corresponsing regulatory dataset. A "-" sign indicates that an association is underrepresented (depleted). The "adj.P.Val" column shows whether a difference in the associations between the clusters is statistically significantly different. The last column shows descriptions of the regulatory datasets. The tables were sorted by "adj.P.Val" column; the top 10 or less most significantly different associations are shown.

```{r limmaOnClusters3, warning=FALSE}
eset<-new("ExpressionSet", exprs=as.matrix(mtx[, eset.labels]))
# Make model matrix
design<-model.matrix(~ 0+factor(eset.groups)) 
colnames(design)<-paste("c", unique(eset.groups), sep="")
# Create an empty square matrix to hold counts of DEGs
degs.matrix<-matrix(0, length(c$lower), length(c$lower))
colnames(degs.matrix)<-paste("c", seq(1,length(c$lower)), sep="")
rownames(degs.matrix)<-paste("c", seq(1, length(c$lower)), sep="") 
unlink(fn_degs)
for(i in colnames(design)){ 
  for(j in colnames(design)){
    # Test only unique pairs of clusters
    if (as.numeric(sub("c", "", i)) < as.numeric(sub("c", "", j))) {
      # Contrasts between two clusters
      contrast.matrix<-makeContrasts(contrasts=paste(i, j, sep="-"), levels=design)
      fit <- lmFit(eset, design) 
      fit2 <- contrasts.fit(fit, contrast.matrix)
      fit2 <- eBayes(fit2)
      degs<-topTable(fit2, number=dim(exprs(eset))[[1]], adjust.method="BH") # , p.value=cutoff.pval, lfc=cutoff.lfc)
      if(nrow(degs)>0) {
        # Average values in clusters i and j
        i.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", i))], nrow=nrow(degs)))
        j.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", j))], nrow=nrow(degs)))
        # Merge and convert the values
        degs.pvals.log <- cbind(i.av, j.av)
        degs.pvals <- matrix(0, nrow=nrow(degs.pvals.log), ncol=ncol(degs.pvals.log), dimnames=list(rownames(degs.pvals.log), c(i, j))) # Empty matrix to hold converted p
        for (ii in 1:nrow(degs.pvals.log)) {
          for (jj in 1:ncol(degs.pvals.log)) {
            if (degs.pvals.log[ii, jj] < 0) {sign = -1} else {sign = 1}
            degs.pvals[ii, jj] <- sign/10^abs(degs.pvals.log[ii, jj])
          }
        }
        degs <- cbind(degs, degs.pvals) # Bind the differences p-values with the converted averaged association p-values
        degs <- degs[ degs$adj.P.Val < 0.1 & (abs(degs[, 7]) < 0.01 | abs(degs[, 8]) < 0.01), ] # Filter non-significant differences. Warning: Hardcoded thresholds
        if(dim(degs)[[1]] > 0) {
          ndegs <- nrow(degs) # The number of differentially associated regulatory datasets
          degs <- degs[order(degs$adj.P.Val, decreasing=F), ] # Order them by the ratio of the differences
          print(paste(i, "vs.", j, ", number of degs significant at adj.p.val<0.5:", ndegs))
          # Keep the number of DEGs in the matrix
          degs.matrix[as.numeric(sub("c", "", i)), as.numeric(sub("c", "", j))] <- ndegs
          degs.table <- merge(degs, trackDb.hg19, by="row.names", all.x=TRUE, sort=FALSE) # Merge with the descriptions
          if(ndegs > 10) { ndegs <- 10 }
          pandoc.table(degs.table[1:ndegs, c(1, 8, 9, 6, 10)])
          write.table(degs.table[, c(1, 8, 9, 6, 10)], fn_degs, sep="\t", quote=F,  col.names=NA, append=T)
        }
      }
    } 
  }
}
print("Counts of regulatory elements differentially associated with each group")
pander(degs.matrix)
```

Summary
---
The cluster 2 was the most different from cluster 1 and cluster 4. Disease- and trait associated SNPs from this cluster were enriched in signal  B-cells, such as Gm12878 B-cell leukemia and other cells from Gm family of cell types, CD20+ B Lymphocytes. 

Most significantly enriched in cluster 2 were H3K9me3, H3K4me1, H3K9ac, H3K4me1, H3K27me3, H2A.Z, H3K4me2, H3K4me2 histone modification marks, and the NFkB, CTCF and MTA3 transcription factor binding sites

| Cell_type | Frequency |   |   Factor  | Frequency |
|:---------:|:---------:|---|:---------:|:---------:|
|  gm12878  |     75    |   |   dnasei  |     45    |
|   cd20+   |     12    |   |    pol2   |     25    |
|    th1    |     12    |   |  h3k4me3  |     23    |
|  gm12892  |     10    |   |  pol2-4h8 |     11    |
|    th2    |     10    |   |   faire   |     6     |
|   dnd41   |     9     |   |  h3k4me2  |     5     |
|  gm12865  |     9     |   |  rna-pet  |     5     |
|  gm12891  |     9     |   |  h3k4me1  |     5     |
|    treg   |     6     |   |   h3k9ac  |     4     |
|  gm06990  |     5     |   |    atf2   |     4     |
|    cd4+   |     4     |   |   stat5a  |     4     |
|  gm12864  |     4     |   |  h3k27ac  |     4     |
|  gm18505  |     3     |   |    mta3   |     4     |
|  hela-s3  |     3     |   |   runx3   |     4     |
|  gm12875  |     2     |   |  h3k9me3  |     3     |
|  gm19193  |     2     |   |    h2az   |     3     |
|   cd14+   |     2     |   |  h3k27me3 |     3     |
|  gm18507  |     2     |   |    p300   |     2     |
|  gm15510  |     2     |   |   foxm1   |     2     |
|    th17   |     1     |   |   nfatc1  |     2     |
|    hcm    |     1     |   |    chd1   |     2     |
|  nhdf-neo |     1     |   |   bclaf1  |     2     |
|   hepg2   |     1     |   |   tblr1   |     2     |
|    nh-a   |     1     |   |  bhlhe40  |     2     |
|    hsmm   |     1     |   |    ctcf   |     2     |
|    k562   |     1     |   |    cnv    |     2     |
|  gm10847  |     1     |   |    pml    |     2     |
|  hct-116  |     1     |   |    nfic   |     2     |
|    raji   |     1     |   |    whip   |     2     |
|           |           |   |    nfkb   |     2     |
|           |           |   |    ebf1   |     2     |
|           |           |   |  h3k79me2 |     1     |
|           |           |   |    ezh2   |     1     |
|           |           |   |    mxi1   |     1     |
|           |           |   |  h4k20me1 |     1     |
|           |           |   | junctions |     1     |

Co-morbidity similarity analysis
---
We used the data from [Hidalgo CA, Blumm N, Barabasi A-L, Christakis NA. PLoS Computational Biology, 5(4):e1000353 doi:10.1371/journal.pcbi.1000353](http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1000353), available at [http://barabasilab.neu.edu/projects/hudine/resource/data/data.html](http://barabasilab.neu.edu/projects/hudine/resource/data/data.html). These data provide co-morbidity measurements among pairs of diseases. We map autoimmune disease- and trait names to 3-digits ICD9 codes and evaluate how co-morbidity measurements correlate with regulatory similarity measurements. We used Phi measurement of co-morbidity. The Spearman correlation coefficient of Phi and regulatory similarity is:


```{r diseaseNetwork3, echo=FALSE}
# Create empty matrix of term disease-disease relationships ($V5 - co-occurrence)
term.ICD9.occur <- matrix(0, nrow=nrow(term.mapping), ncol=nrow(term.mapping))
rownames(term.ICD9.occur) <- term.mapping$term
colnames(term.ICD9.occur) <- term.mapping$term
# Create two others, to hold relative risk ($V6) and phi-correlation ($V9)
term.ICD9.risk <- term.ICD9.occur; term.ICD9.phi <- term.ICD9.occur
# Populate this matrix with Barabasi relationship values
for (i in 1:nrow(term.mapping)) {
  for (j in 1:nrow(term.mapping)) {
    # The disease associations matrix is not symmetrical - we pull up the index with either disease1-disease2 relationship, or disease2-disease1 relationship
    idx <- (mtx.disease$V1 == term.mapping$ICD9[i] & mtx.disease$V2 == term.mapping$ICD9[j]) | (mtx.disease$V2 == term.mapping$ICD9[i] & mtx.disease$V1 == term.mapping$ICD9[j])
    # If relationship pair is found, store it. Self-self relationships will be 0
    if (sum(idx) == 1) { 
    term.ICD9.occur[i, j] <- mtx.disease$V5[idx]
    term.ICD9.risk[i, j] <- mtx.disease$V6[idx]
    term.ICD9.phi[i, j] <- mtx.disease$V9[idx]  
    }
  }
  # For each row, replace self-self associations (zeros) by row maximum
  term.ICD9.occur[i, term.ICD9.occur[i, ] == 0] <- max(term.ICD9.occur[i, ]) + 0.01
  term.ICD9.risk[i, term.ICD9.risk[i, ] == 0] <- max(term.ICD9.risk[i, ]) + 0.01
  term.ICD9.phi[i, term.ICD9.phi[i, ] == 0] <- max(term.ICD9.phi[i, ]) + 0.01
}
```

```{r diseaseNetwork, echo=FALSE}
# Finally, check correlation between pairwise relationships
# print("Co-occurrence")
# term.ICD9.occur.melt <- melt(term.ICD9.occur)
# term.cor.occur <- left_join(mtx.cor.melt, term.ICD9.occur.melt, by=c("Var1" = "Var1", "Var2" = "Var2"))
# #term.cor.occur <- term.cor.occur[ term.cor.occur$Var1 != term.cor.occur$Var2, ]
# (rcorr(term.cor.occur$value.x, term.cor.occur$value.y))
# print("Relative risk")
# term.ICD9.risk.melt <- melt(term.ICD9.risk)
# term.cor.risk <- left_join(mtx.cor.melt, term.ICD9.risk.melt, by=c("Var1" = "Var1", "Var2" = "Var2"))
# #term.cor.risk <- term.cor.risk[ term.cor.risk$Var1 != term.cor.risk$Var2, ]
# (rcorr(term.cor.risk$value.x, term.cor.risk$value.y))
# print("Phi-correlation")
term.ICD9.phi.melt <- melt(term.ICD9.phi)
term.cor.phi <- left_join(mtx.cor.melt, term.ICD9.phi.melt, by=c("Var1" = "Var1", "Var2" = "Var2"))
#term.cor.phi <- term.cor.phi[ term.cor.phi$Var1 != term.cor.phi$Var2, ]
(rcorr(term.cor.phi$value.x, term.cor.phi$value.y)[[1]][1, 2])
```

Iridescent literature similarity
---

```{r iridescent, echo=FALSE}
iridescent <- read.table("data/iridescent.txt", sep="\t", head=T)
#x <- iridescent %>%
#  select(Entity..A., Implicit.relationship..C., Shared.rels) %>%
#  spread(key = Implicit.relationship..C., Shared.rels)
#y <- x %>% gather(key = variable, value = temp, -Entity..A.)
# Re-map iridescent names to tumorportal names
tmp1 <- left_join(iridescent, term.mapping, by=c("term1" = "iridescent"))
tmp2 <- left_join(tmp1, term.mapping, by=c("term2" = "iridescent"))
iridescent.names <- tmp2[, c(11, 9, 3:8)] # Reconstruct original dataset
colnames(iridescent.names)[1:2] <- c("term1", "term2")

#mtx.cor.melt <- melt(mtx.cor[[1]])
mtx.cor.irid <- left_join(mtx.cor.melt, iridescent.names, by=c("Var1" = "term1", "Var2" = "term2"))
colnames(mtx.cor.irid)[1:3] <- c("term1", "term2", "episim")

for (i in 4:9) {
  print(paste(colnames(mtx.cor.irid)[i], "correlation with regulatory similarity"))
  print(rcorr(mtx.cor.irid$episim, mtx.cor.irid[, i], type="spearman")[[1]][1, 2])
}
```


Analysis of TFBSs
===
We also performed regulatory similarity analysis using subsets of regulatory datasets, such as Transcription Factor Binding Sites or Histone Modification Marks. Here, out of all regulatory datasets, we selected only TFBSs.

```{r loadData1, echo=FALSE}
# Define output and data subfolders to use, change to analyze different data
rname<-"results//" # Output folder
# One or more GenomeRunner Web results data folders.
dname <- "data.gr//ENCODE_FDR/"
mtx<-do.call("rbind", lapply(dname, function(fn) as.matrix(read.table(paste(fn, "matrix.txt", sep=""), sep="\t", header=T, row.names=1))))
mtx <- mtx[grep("tfbs", rownames(mtx), ignore.case=T), ] # Limit the GFs to TFBSs and Histone marks
# Exploratory: check quantiles and remove diseaases showing no enrichments
# mtx.sumstat <- as.data.frame(apply(mtx, 2, quantile)) # Get quantiles
# mtx <- mtx[ , apply(mtx.sumstat, 2, function(x) sum(abs(x)) != 5)] # REmove those that have all "1" or "-1"
# Optional: filter unused genomic features
# mtx<-mtx[grep("snp", rownames(mtx), ignore.case=T, invert=T), ]
mtx<-mtx.transform(mtx) # -log10 transform p-values
# Optional: adjust columns for multiple testing. See utils.R for the function definition.
# mtx<-mtx.adjust(mtx) 
trackDb.hg19 <- read.table("data.gr//gf_descriptions.hg19.txt", sep="\t", row.names=1)
# Define file names for results output
fn_maxmin <- "results//maxmin_correlations_tfbs.txt"
fn_clust <- "results/clustering_tfbs.txt"
fn_degs <- "results/clusters-degs_tfbs.txt"
```

```{r preprocessData1, echo=FALSE}
dim(mtx) # Check original dimensions
# Define minimum number of times a row/col should have values above the cutoffs
numofsig<-1
cutoff<- -log10(0.1) # q-value significance cutoff
# What remains if we remove rows/cols with nothing significant
dim(mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ])
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig])
# Trim the matrix
mtx<-mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ]
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig]
```

```{r preprocessCorrel1, echo=FALSE}
# rcorr returns a list, [[1]] - correl coeffs, [[3]] - p-values. Type - pearson/spearman
mtx.cor<-rcorr(as.matrix(mtx), type="spearman")
# Optionally, try kendall correlation
# mtx.cor[[1]]<-cor(as.matrix(mtx), method="kendall")
```

Next, we visualized heatmap of regulatory similarity. 

```{r epigenomicVisualization1, echo=FALSE}
par(oma=c(5,0,0,5), mar=c(10, 4.1, 4.1, 5)) # Adjust margins
color<-colorRampPalette(c("blue","yellow")) # Define color gradient
#color<-greenred #Standard green-black-red palette
# Adjust clustering parameters.
# Distance: "euclidean", "maximum","manhattan" or "minkowski". Do not use "canberra" or "binary"
# Clustering: "ward", "single", "complete", "average", "mcquitty", "median" or "centroid"
dist.method<-"euclidean"  
hclust.method<-"ward.D2"
# Setting breaks to go from minimum to maximum correlation coefficients,
# excluding min/max outliers. This way we get rid of diagonale of 1's
granularity = 10
my.breaks <- seq(min(mtx.cor[[1]][mtx.cor[[1]]!=min(mtx.cor[[1]])]),
                 max(mtx.cor[[1]][mtx.cor[[1]]!=max(mtx.cor[[1]])]),
                 length.out=(2*granularity + 1))
h<-heatmap.2(as.matrix(mtx.cor[[1]]), trace="none", density.info="none", col=color, distfun=function(x){dist(x, method=dist.method)}, hclustfun=function(x){hclust(x, method=hclust.method)}, cexRow=0.7, cexCol=0.7, breaks=my.breaks)
# write.table(melt(mtx.cor[[1]][h$rowInd, h$colInd]), "results/term.cor.txt", sep="\t", quote=F, row.names=F, col.names=F)
```

and checked how well it correlates with original shared genetic overlap clustering:

```{r RegOverlapCorrel_own, eval=FALSE}
# Using self-made overlap matrix
mtx.cor.melt <- melt(mtx.cor[[1]]) # Convert correlation matrix to long format
c <- left_join(mtx.overlap, mtx.cor.melt, by = c("V1" = "Var1", "V2" = "Var2"))
(rcorr(c[, 3], c[, 4], type="spearman")[[1]][1, 2]) # Finally, correlation between the two
```

```{r RegOverlapCorrel_original}
# Using authors-provided overlap matrix
mtx.cor.melt <- melt(mtx.cor[[1]]) # Convert correlation matrix to long format
c <- left_join(mtx.fig1a.melt, mtx.cor.melt, by=c("term1" = "Var1", "term2" = "Var2"))
(rcorr(c[, 3], c[, 4], type="spearman")[[1]][1, 2]) # Finally, correlation between the two
```

The top 10 pairs of disease-associated SNPs are most similar with each other.

```{r maxMin1, echo=FALSE}
# Checking max/min correlations
mtx.cor1<-mtx.cor[[1]]
diag(mtx.cor1)<-0 # We don't need to consider self correlations, zero them out
mtx.cor1[lower.tri(mtx.cor1)] <- 0 # Also zero out one matrix triangle, to avoid duplicate pairs
mtx.maxMin <- melt(mtx.cor1) # Convert the matrix into tidy data
mtx.maxMin <- mtx.maxMin[order(mtx.maxMin$value, decreasing=T), ] # Reorder the data by maxMin correlation
mtx.maxMin <- mtx.maxMin[mtx.maxMin$value != 0, ]
row.names(mtx.maxMin) <- NULL
colnames(mtx.maxMin) <- c("Disease 1", "Disease 2", "Corr. coefficient")
pander(head(mtx.maxMin, n=10))
write.table(mtx.maxMin, fn_maxmin, sep="\t", quote=F,  row.names=F)
mtx.maxMin.tfbs <- data.frame(coef=mtx.maxMin[, 3]) # Save the data for future plotting
mtx.maxMin.tfbs$type <- "tfbs" # Label it
```

The similarity dendrogram can be divided into separate clusters:

```{r defineClusters1, echo=FALSE}
par(oma=c(0, 0, 0, 0), mar=c(5.1, 4.1, 4.1,25.1), cex=0.5)
# Plot the dendrogram only, limit y axis. attr(h$colDendrogram, "height") has the maximum height of the dendrogram.
plot(h$colDendrogram, horiz=T) 
# Cut the dentrogram into separate clusters. Tweak the height
abline(v=3) # Visually evaluate the height where to cut
c<-cut(h$colDendrogram, h=3) 
# Check the number of clusters, and the number of members.
for (i in 1:length(c$lower)){
  cat(paste("Cluster", formatC(i, width=2, flag="0"), sep=""), "has", formatC(attr(c$lower[[i]], "members"), width=3), "members", "\n")
  cat(paste(t(labels(c$lower[[i]])), collapse="\n"))
  cat(paste("\n", "\n"))
}
# Output the results into a file
unlink(fn_clust)
for (i in 1:length(c$lower)){ 
  write.table(paste(i, t(labels(c$lower[[i]])), sep="\t"), fn_clust, sep="\t", quote=F,  col.names=F, row.names=F, append=T)
}
```

The "Enrichment 1/2" columns show the average p-values of the group-specific SNPs-regulatory associations. A "-" sign indicates that an association is underrepresented. The "p-value" column shows whether the difference in the associations between the groups is statistically significantly different.

```{r defineGroups1, echo=FALSE}
eset.labels<-character() # Empty vector to hold cluster labels
eset.groups<-numeric() # Empty vector to hold cluster groups
# Set the minimum number of members to be considered for the differential analysis
minmembers<-3
for (i in 1:length(c$lower)) { # Go through each cluster
  # If the number of members is more than a minimum number of members
  if (attr(c$lower[[i]], "members") > minmembers) { 
    eset.labels<-append(eset.labels, labels(c$lower[[i]]))
    eset.groups<-append(eset.groups, rep(i, length(labels(c$lower[[i]]))))
  }
}
```

```{r limmaOnClusters1, warning=FALSE}
eset<-new("ExpressionSet", exprs=as.matrix(mtx[, eset.labels]))
# Make model matrix
design<-model.matrix(~ 0+factor(eset.groups)) 
colnames(design)<-paste("c", unique(eset.groups), sep="")
# Create an empty square matrix to hold counts of DEGs
degs.matrix<-matrix(0, length(c$lower), length(c$lower))
colnames(degs.matrix)<-paste("c", seq(1,length(c$lower)), sep="")
rownames(degs.matrix)<-paste("c", seq(1, length(c$lower)), sep="") 
unlink(fn_degs)
for(i in colnames(design)){ 
  for(j in colnames(design)){
    # Test only unique pairs of clusters
    if (as.numeric(sub("c", "", i)) < as.numeric(sub("c", "", j))) {
      # Contrasts between two clusters
      contrast.matrix<-makeContrasts(contrasts=paste(i, j, sep="-"), levels=design)
      fit <- lmFit(eset, design) 
      fit2 <- contrasts.fit(fit, contrast.matrix)
      fit2 <- eBayes(fit2)
      degs<-topTable(fit2, number=dim(exprs(eset))[[1]], adjust.method="BH") # , p.value=cutoff.pval, lfc=cutoff.lfc)
      if(nrow(degs)>0) {
        # Average values in clusters i and j
        i.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", i))], nrow=nrow(degs)))
        j.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", j))], nrow=nrow(degs)))
        # Merge and convert the values
        degs.pvals.log <- cbind(i.av, j.av)
        degs.pvals <- matrix(0, nrow=nrow(degs.pvals.log), ncol=ncol(degs.pvals.log), dimnames=list(rownames(degs.pvals.log), c(i, j))) # Empty matrix to hold converted p
        for (ii in 1:nrow(degs.pvals.log)) {
          for (jj in 1:ncol(degs.pvals.log)) {
            if (degs.pvals.log[ii, jj] < 0) {sign = -1} else {sign = 1}
            degs.pvals[ii, jj] <- sign/10^abs(degs.pvals.log[ii, jj])
          }
        }
        degs <- cbind(degs, degs.pvals) # Bind the differences p-values with the converted averaged association p-values
        degs <- degs[ degs$adj.P.Val < 0.1 & (abs(degs[, 7]) < 0.01 | abs(degs[, 8]) < 0.01), ] # Filter non-significant differences. Warning: Hardcoded thresholds
        if(dim(degs)[[1]] > 0) {
          ndegs <- nrow(degs) # The number of differentially associated regulatory datasets
          degs <- degs[order(degs$adj.P.Val, decreasing=F), ] # Order them by the ratio of the differences
          print(paste(i, "vs.", j, ", number of degs significant at adj.p.val<0.5:", ndegs))
          # Keep the number of DEGs in the matrix
          degs.matrix[as.numeric(sub("c", "", i)), as.numeric(sub("c", "", j))] <- ndegs
          degs.table <- merge(degs, trackDb.hg19, by="row.names", all.x=TRUE, sort=FALSE) # Merge with the descriptions
          if(ndegs > 10) { ndegs <- 10 }
          pander(degs.table[1:ndegs, c(1, 8, 9, 6, 10)])
          write.table(degs.table[, c(1, 8, 9, 6, 10)], fn_degs, sep="\t", quote=F,  col.names=NA, append=T)
        }
      }
    } 
  }
}
print("Counts of regulatory elements differentially associated with each group")
pander(degs.matrix)
```

**Text mining question 2:** Are the terms associated stronger with the diseases in one vs. the other cluster based on the literature strength? Are the terms themselves related based on the literature? *Expected answer:* Yes, the literature associations should confirm the relationships.

Summary
---
1. There are 4 clusters. The first cluster drives all the differences.

|    | C1 | C2                                                      | C3                                                       | C4                                                       |
|----|----|---------------------------------------------------------|----------------------------------------------------------|----------------------------------------------------------|
| C1 |    | Cell types: Gm12878 Reg: NFkB, Pol2, MTA3, NFIC, NFATC1 | Cell types: Gm12878  Reg: NFkB, Pol2, MTA3, NFIC, NFATC1 | Cell types: Gm12878  Reg: NFkB, Pol2, MTA3, NFIC, NFATC1 |
| C2 |    |                                                         | Nothing significant                                      | Nothing significant                                      |
| C3 |    |                                                         |                                                          | Nothing significant                                      |
| C4 |    |                                                         |                                                          |                                                          |

Analysis of histone marks
===
Out of all regulatory datasets, we select only histone marks

```{r loadData2, echo=FALSE}
# Define output and data subfolders to use, change to analyze different data
rname<-"results//" # Output folder
# One or more GenomeRunner Web results data folders.
dname <- "data.gr//ENCODE_FDR/"
mtx<-do.call("rbind", lapply(dname, function(fn) as.matrix(read.table(paste(fn, "matrix.txt", sep=""), sep="\t", header=T, row.names=1))))
mtx <- mtx[grep("histone", rownames(mtx), ignore.case=T), ] # Limit the GFs to TFBSs and Histone marks
# Exploratory: check quantiles and remove diseaases showing no enrichments
# mtx.sumstat <- as.data.frame(apply(mtx, 2, quantile)) # Get quantiles
# mtx <- mtx[ , apply(mtx.sumstat, 2, function(x) sum(abs(x)) != 5)] # REmove those that have all "1" or "-1"
# Optional: filter unused genomic features
# mtx<-mtx[grep("snp", rownames(mtx), ignore.case=T, invert=T), ]
mtx<-mtx.transform(mtx) # -log10 transform p-values
# Optional: adjust columns for multiple testing. See utils.R for the function definition.
# mtx<-mtx.adjust(mtx) 
trackDb.hg19 <- read.table("data.gr//gf_descriptions.hg19.txt", sep="\t", row.names=1)
fn_maxmin <- "results//maxmin_correlations_histone.txt"
fn_clust <- "results/clustering_histone.txt"
fn_degs <- "results/clusters-degs_histone.txt"
```

```{r preprocessData2, echo=FALSE}
dim(mtx) # Check original dimensions
# Define minimum number of times a row/col should have values above the cutoffs
numofsig<-1
cutoff<- -log10(0.1) # q-value significance cutoff
# What remains if we remove rows/cols with nothing significant
dim(mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ])
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig])
# Trim the matrix
mtx<-mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ]
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig]
```

```{r preprocessCorrel2, echo=FALSE}
# rcorr returns a list, [[1]] - correl coeffs, [[3]] - p-values. Type - pearson/spearman
mtx.cor<-rcorr(as.matrix(mtx), type="spearman")
# Optionally, try kendall correlation
# mtx.cor[[1]]<-cor(as.matrix(mtx), method="kendall")
```

Next, we visualize heatmap of regulatory similarity. 

```{r epigenomicVisualization2, echo=FALSE}
par(oma=c(5,0,0,5), mar=c(10, 4.1, 4.1, 5)) # Adjust margins
color<-colorRampPalette(c("blue","yellow")) # Define color gradient
#color<-greenred #Standard green-black-red palette
# Adjust clustering parameters.
# Distance: "euclidean", "maximum","manhattan" or "minkowski". Do not use "canberra" or "binary"
# Clustering: "ward", "single", "complete", "average", "mcquitty", "median" or "centroid"
dist.method<-"euclidean"  
hclust.method<-"ward.D2"
# Setting breaks to go from minimum to maximum correlation coefficients,
# excluding min/max outliers. This way we get rid of diagonale of 1's
granularity = 10
my.breaks <- seq(min(mtx.cor[[1]][mtx.cor[[1]]!=min(mtx.cor[[1]])]),
                 max(mtx.cor[[1]][mtx.cor[[1]]!=max(mtx.cor[[1]])]),
                 length.out=(2*granularity + 1))
h<-heatmap.2(as.matrix(mtx.cor[[1]]), trace="none", density.info="none", col=color, distfun=function(x){dist(x, method=dist.method)}, hclustfun=function(x){hclust(x, method=hclust.method)}, cexRow=0.7, cexCol=0.7, breaks=my.breaks)
```

```{r RegOverlapCorrel2_own, eval=FALSE}
# Using self-made overlap matrix
mtx.cor.melt <- melt(mtx.cor[[1]]) # Convert correlation matrix to long format
c <- left_join(mtx.overlap, mtx.cor.melt, by = c("V1" = "Var1", "V2" = "Var2"))
(rcorr(c[, 3], c[, 4], type="spearman")[[1]][1, 2]) # Finally, correlation between the two
```

```{r RegOverlapCorrel2_original}
# Using authors-provided overlap matrix
mtx.cor.melt <- melt(mtx.cor[[1]]) # Convert correlation matrix to long format
c <- left_join(mtx.fig1a.melt, mtx.cor.melt, by=c("term1" = "Var1", "term2" = "Var2"))
(rcorr(c[, 3], c[, 4], type="spearman")[[1]][1, 2]) # Finally, correlation between the two
```

The top 10 pairs of autoimmune-associated SNPs are most similar with each other.

```{r maxMin2, echo=FALSE}
# Checking max/min correlations
mtx.cor1<-mtx.cor[[1]]
diag(mtx.cor1)<-0 # We don't need to consider self correlations, zero them out
mtx.cor1[lower.tri(mtx.cor1)] <- 0 # Also zero out one matrix triangle, to avoid duplicate pairs
mtx.maxMin <- melt(mtx.cor1) # Convert the matrix into tidy data
mtx.maxMin <- mtx.maxMin[order(mtx.maxMin$value, decreasing=T), ] # Reorder the data by maxMin correlation
mtx.maxMin <- mtx.maxMin[mtx.maxMin$value != 0, ]
row.names(mtx.maxMin) <- NULL
colnames(mtx.maxMin) <- c("Disease 1", "Disease 2", "Corr. coefficient")
pander(head(mtx.maxMin, n=10))
write.table(mtx.maxMin, fn_maxmin, sep="\t", quote=F,  row.names=F)
mtx.maxMin.histone <- data.frame(coef=mtx.maxMin[, 3]) # Save the data for future plotting
mtx.maxMin.histone$type <- "histone" # Label it
```

The similarity dendrogram can be divided into separate groups:

```{r defineClusters2, echo=FALSE}
par(oma=c(0, 0, 0, 0), mar=c(5.1, 4.1, 4.1,25.1), cex=0.5)
# Plot the dendrogram only, limit y axis. attr(h$colDendrogram, "height") has the maximum height of the dendrogram.
plot(h$colDendrogram, horiz=T) 
# Cut the dentrogram into separate clusters. Tweak the height
abline(v=2.8) # Visually evaluate the height where to cut
c<-cut(h$colDendrogram, h=2.8) 
# Check the number of clusters, and the number of members.
for (i in 1:length(c$lower)){
  cat(paste("Cluster", formatC(i, width=2, flag="0"), sep=""), "has", formatC(attr(c$lower[[i]], "members"), width=3), "members", "\n")
  cat(paste(t(labels(c$lower[[i]])), collapse="\n"))
  cat(paste("\n", "\n"))
}
# Output the results into a file
unlink(fn_clust)
for (i in 1:length(c$lower)){ 
  write.table(paste(i, t(labels(c$lower[[i]])), sep="\t"), fn_clust, sep="\t", quote=F,  col.names=F, row.names=F, append=T)
}
```

The "Enrichment 1/2" columns show the average p-values of the group-specific SNPs-regulatory associations. A "-" sign indicates that an association is underrepresented. The "p-value" column shows whether the difference in the associations bwtween the groups is statistically significantly different.

```{r defineGroups2, echo=FALSE}
eset.labels<-character() # Empty vector to hold cluster labels
eset.groups<-numeric() # Empty vector to hold cluster groups
# Set the minimum number of members to be considered for the differential analysis
minmembers<-3
for (i in 1:length(c$lower)) { # Go through each cluster
  # If the number of members is more than a minimum number of members
  if (attr(c$lower[[i]], "members") > minmembers) { 
    eset.labels<-append(eset.labels, labels(c$lower[[i]]))
    eset.groups<-append(eset.groups, rep(i, length(labels(c$lower[[i]]))))
  }
}
```

```{r limmaOnClusters2, warning=FALSE}
eset<-new("ExpressionSet", exprs=as.matrix(mtx[, eset.labels]))
# Make model matrix
design<-model.matrix(~ 0+factor(eset.groups)) 
colnames(design)<-paste("c", unique(eset.groups), sep="")
# Create an empty square matrix to hold counts of DEGs
degs.matrix<-matrix(0, length(c$lower), length(c$lower))
colnames(degs.matrix)<-paste("c", seq(1,length(c$lower)), sep="")
rownames(degs.matrix)<-paste("c", seq(1, length(c$lower)), sep="") 
unlink(fn_degs)
for(i in colnames(design)){ 
  for(j in colnames(design)){
    # Test only unique pairs of clusters
    if (as.numeric(sub("c", "", i)) < as.numeric(sub("c", "", j))) {
      # Contrasts between two clusters
      contrast.matrix<-makeContrasts(contrasts=paste(i, j, sep="-"), levels=design)
      fit <- lmFit(eset, design) 
      fit2 <- contrasts.fit(fit, contrast.matrix)
      fit2 <- eBayes(fit2)
      degs<-topTable(fit2, number=dim(exprs(eset))[[1]], adjust.method="BH") # , p.value=cutoff.pval, lfc=cutoff.lfc)
      if(nrow(degs)>0) {
        # Average values in clusters i and j
        i.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", i))], nrow=nrow(degs)))
        j.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", j))], nrow=nrow(degs)))
        # Merge and convert the values
        degs.pvals.log <- cbind(i.av, j.av)
        degs.pvals <- matrix(0, nrow=nrow(degs.pvals.log), ncol=ncol(degs.pvals.log), dimnames=list(rownames(degs.pvals.log), c(i, j))) # Empty matrix to hold converted p
        for (ii in 1:nrow(degs.pvals.log)) {
          for (jj in 1:ncol(degs.pvals.log)) {
            if (degs.pvals.log[ii, jj] < 0) {sign = -1} else {sign = 1}
            degs.pvals[ii, jj] <- sign/10^abs(degs.pvals.log[ii, jj])
          }
        }
        degs <- cbind(degs, degs.pvals) # Bind the differences p-values with the converted averaged association p-values
        degs <- degs[ degs$adj.P.Val < 0.1 & (abs(degs[, 7]) < 0.01 | abs(degs[, 8]) < 0.01), ] # Filter non-significant differences. Warning: Hardcoded thresholds
        if(dim(degs)[[1]] > 0) {
          ndegs <- nrow(degs) # The number of differentially associated regulatory datasets
          degs <- degs[order(degs$adj.P.Val, decreasing=F), ] # Order them by the ratio of the differences
          print(paste(i, "vs.", j, ", number of degs significant at adj.p.val<0.5:", ndegs))
          # Keep the number of DEGs in the matrix
          degs.matrix[as.numeric(sub("c", "", i)), as.numeric(sub("c", "", j))] <- ndegs
          degs.table <- merge(degs, trackDb.hg19, by="row.names", all.x=TRUE, sort=FALSE) # Merge with the descriptions
          if(ndegs > 10) { ndegs <- 10 }
          pander(degs.table[1:ndegs, c(1, 8, 9, 6, 10)])
          write.table(degs.table[, c(1, 8, 9, 6, 10)], fn_degs, sep="\t", quote=F,  col.names=NA, append=T)
        }
      }
    } 
  }
}
print("Counts of regulatory elements differentially associated with each group")
pander(degs.matrix)
```

**Text mining question 2:** Are the terms associated stronger with the diseases in one vs. the other cluster based on the literature strength? Are the terms themselves related based on the literature? *Expected answer:* Yes, the literature associations should confirm the relationships.

Summary
---

1. Again, cluster 1 is strongly distinct. Cluster 2 is less so. Histone marks seem all active.

|    | C1 | C2                                                                                | C3                                                                                | C4                                                                                |
|----|----|-----------------------------------------------------------------------------------|-----------------------------------------------------------------------------------|-----------------------------------------------------------------------------------|
| C1 |    | Cell types: Gm12878, CD20+  Reg: H3K4me1, H3K9me3, H3K9ac, H3K27ac, H2az, H3K4me2 | Cell types: Gm12878, CD20+  Reg: H3K4me1, H3K9me3, H3K9ac, H3K27ac, H2az, H3K4me2 | Cell types: Gm12878, CD20+  Reg: H3K4me1, H3K9me3, H3K9ac, H3K27ac, H2az, H3K4me2 |
| C2 |    |                                                                                   | Cell types: K562, NHEK, NHDF-Ad, NH-A, HMEC  Reg: H3K36me3, H4K20me1, H3K79me2    | Nothing significant                                                               |
| C3 |    |                                                                                   |                                                                                   | Nothing significant                                                               |
| C4 |    |                                                                                   |                                                                                   |                                                                                   |


Distribution of maxMin correlation coefficients
---
```{r maxMinHist}
maxmin <- rbind(mtx.maxMin.tfbs, mtx.maxMin.histone, mtx.maxMin.all)
ggplot(maxmin, aes(coef, fill=type)) + geom_density(alpha=0.2)
```


```{r eval=FALSE}
# SNOMED literature analysis
snomed <- read.table("data/Bridget//tfbs.snomed.vector.mat", sep="\t", header=T, stringsAsFactors=F)
colnames(snomed) <-sub("_1", "", colnames(snomed)); colnames(snomed) <-sub("_2", "", colnames(snomed))
rownames(snomed) <-sub("_1", "", rownames(snomed)); rownames(snomed) <-sub("_2", "", rownames(snomed))

snomed <- cbind(term=rownames(snomed), snomed)
snomed.melt <- melt(snomed)

mtx.cor.snomed <- left_join(mtx.cor.melt, snomed.melt, by=c("Var1" = "term", "Var2" = "variable"))

```


