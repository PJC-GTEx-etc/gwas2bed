---
title: "Genetic and epigenetic fine mapping of causal autoimmune disease variants"
author: "Mikhail Dozmorov"
date: "November 1, 2014"
output: html_document
---
```{r setup, echo=FALSE}
source("utils.R")
suppressMessages(library(Hmisc)) # For rcorr function
suppressMessages(library(gplots))
suppressMessages(library(Biobase))
suppressMessages(library(limma))
library(reshape2)
library(dplyr)
library(ggplot2)
#library(qvalue)
# Set up the environment
library(knitr) 
opts_chunk$set(cache.path='cache/', fig.path='img/', cache=F, tidy=T, fig.keep='high', echo=F, dpi=300, out.width=700)
options(replace.assign=TRUE, width=120)
suppressMessages(library(pander))
panderOptions('table.split.table', Inf)
set.seed(1)
```

[Genetic and epigenetic fine mapping of causal autoimmune disease variants](http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature13835.pdf)

[Supplemental table 1](http://www.nature.com/nature/journal/vaop/ncurrent/extref/nature13835-s1.xls) has genomic coordinates of disease-associated SNPs.

Original overlap analysis
===
```{r loadOverlapMtx}
mtx.overlap <- read.table("data/overlapMatrix.txt", sep="\t", head=F)
mtx.overlap.carpet <- dcast(mtx.overlap, V1~V2, mean)
rownames(mtx.overlap.carpet) <- mtx.overlap.carpet$V1
mtx.overlap.carpet <- as.matrix(mtx.overlap.carpet[, -1])
mtx.overlap$V1 <- sub(".bed", "", mtx.overlap$V1)
mtx.overlap$V2 <- sub(".bed", "", mtx.overlap$V2)
# We prepare this matrix for measuring correlations
a <- mtx.overlap[!(mtx.overlap[, 1] == mtx.overlap[, 2]), ] # Exclude self-self associations
# rownames(a) <- paste(a[, 1], a[, 2], sep="-") # Make names like term1-term2
# a <- a[, 3, drop=F] # Keep only OVERLAP counts
```

We visualize clustering of disease-specific SNP sets based on the number of overlapping SNPs.

```{r visualizeOverlapMtx}
par(oma=c(5,0,0,5), mar=c(10, 4.1, 4.1, 5)) # Adjust margins
color<-colorRampPalette(c("blue","yellow")) # Define color gradient
#color<-greenred #Standard green-black-red palette
# Adjust clustering parameters.
# Distance: "euclidean", "maximum","manhattan" or "minkowski". Do not use "canberra" or "binary"
# Clustering: "ward", "single", "complete", "average", "mcquitty", "median" or "centroid"
dist.method<-"euclidean"  
hclust.method<-"ward.D2"
# Setting breaks to go from minimum to maximum correlation coefficients,
# excluding min/max outliers. This way we get rid of diagonale of 1's
h<-heatmap.2(mtx.overlap.carpet, trace="none", density.info="none", col=color, distfun=function(x){dist(x, method=dist.method)}, hclustfun=function(x){hclust(x, method=hclust.method)}, cexRow=0.7, cexCol=0.7, scale="row")
```

Analysis of TFBSs
===
Out of all regulatory datasets, we select only TFBSs.

```{r loadData1, echo=FALSE}
# Define output and data subfolders to use, change to analyze different data
rname<-"results//" # Output folder
# One or more GenomeRunner Web results data folders.
dname <- "data.gr//ENCODE_FDR/"
mtx<-do.call("rbind", lapply(dname, function(fn) as.matrix(read.table(paste(fn, "matrix.txt", sep=""), sep="\t", header=T, row.names=1))))
mtx <- mtx[grep("tfbs", rownames(mtx), ignore.case=T), ] # Limit the GFs to TFBSs and Histone marks
# Exploratory: check quantiles and remove diseaases showing no enrichments
# mtx.sumstat <- as.data.frame(apply(mtx, 2, quantile)) # Get quantiles
# mtx <- mtx[ , apply(mtx.sumstat, 2, function(x) sum(abs(x)) != 5)] # REmove those that have all "1" or "-1"
# Optional: filter unused genomic features
# mtx<-mtx[grep("snp", rownames(mtx), ignore.case=T, invert=T), ]
mtx<-mtx.transform(mtx) # -log10 transform p-values
# Optional: adjust columns for multiple testing. See utils.R for the function definition.
# mtx<-mtx.adjust(mtx) 
trackDb.hg19 <- read.table("data.gr//gf_descriptions.hg19.txt", sep="\t", row.names=1)
# Define file names for results output
fn_maxmin <- "results//maxmin_correlations_tfbs.txt"
fn_clust <- "results/clustering_tfbs.txt"
fn_degs <- "results/clusters-degs_tfbs.txt"
```

```{r preprocessData1, echo=FALSE}
dim(mtx) # Check original dimensions
# Define minimum number of times a row/col should have values above the cutoffs
numofsig<-1
cutoff<- -log10(0.1) # q-value significance cutoff
# What remains if we remove rows/cols with nothing significant
dim(mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ])
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig])
# Trim the matrix
mtx<-mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ]
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig]
```

```{r preprocessCorrel1, echo=FALSE}
# rcorr returns a list, [[1]] - correl coeffs, [[3]] - p-values. Type - pearson/spearman
mtx.cor<-rcorr(as.matrix(mtx), type="spearman")
# Optionally, try kendall correlation
# mtx.cor[[1]]<-cor(as.matrix(mtx), method="kendall")
```

We check how regulatory similarity correlates with overlap similarity.

```{r RegOverlapCorrel1}
mtx.cor.melt <- melt(mtx.cor[[1]]) # Convert correlation matrix to long format
b <- mtx.cor.melt[!(mtx.cor.melt[, 1] == mtx.cor.melt[, 2]), , drop=F] # Exclude self-self associations
# rownames(b) <- paste(b[, 1], b[, 2], sep="-") # Make names like term1-term2
# b <- b[, 3, drop=F] # Keep only REGULATORY counts
# c <- merge(a, b, by="row.names") # Combine OVERLAP and REGULATORY counts
c <- left_join(a, b, by = c("V1" = "Var1", "V2" = "Var2"))
(rcorr(c[, 3], c[, 4])) # Finally, correlation between the two
```

Next, we visualize heatmap of regulatory similarity. 

```{r epigenomicVisualization1, echo=FALSE}
par(oma=c(5,0,0,5), mar=c(10, 4.1, 4.1, 5)) # Adjust margins
color<-colorRampPalette(c("blue","yellow")) # Define color gradient
#color<-greenred #Standard green-black-red palette
# Adjust clustering parameters.
# Distance: "euclidean", "maximum","manhattan" or "minkowski". Do not use "canberra" or "binary"
# Clustering: "ward", "single", "complete", "average", "mcquitty", "median" or "centroid"
dist.method<-"euclidean"  
hclust.method<-"ward.D2"
# Setting breaks to go from minimum to maximum correlation coefficients,
# excluding min/max outliers. This way we get rid of diagonale of 1's
granularity = 10
my.breaks <- seq(min(mtx.cor[[1]][mtx.cor[[1]]!=min(mtx.cor[[1]])]),
                 max(mtx.cor[[1]][mtx.cor[[1]]!=max(mtx.cor[[1]])]),
                 length.out=(2*granularity + 1))
h<-heatmap.2(as.matrix(mtx.cor[[1]]), trace="none", density.info="none", col=color, distfun=function(x){dist(x, method=dist.method)}, hclustfun=function(x){hclust(x, method=hclust.method)}, cexRow=0.7, cexCol=0.7, breaks=my.breaks)
# write.table(melt(mtx.cor[[1]][h$rowInd, h$colInd]), "results/term.cor.txt", sep="\t", quote=F, row.names=F, col.names=F)
```

**Text mining question 1:** Are the diseases within a cluster share stronger literature similarity than the diseases between the clusters? To answer, we need literature similarity scores for each pair, then split the pairs into cluster-specific groups and compare score distributions with what can be expected by chance, calculating the p-values for it. *Expected answer:* Diseases within each cluster are related to each other by literature findings stronger than could be expected by chance. Diseases between the clusters are not related to each other by literature findings, and this also may be statistically significant.

The top 10 pairs of disease-associated SNPs are most similar with each other.

```{r maxMin1, echo=FALSE}
# Checking max/min correlations
mtx.cor1<-mtx.cor[[1]]
diag(mtx.cor1)<-0 # We don't need to consider self correlations, zero them out
mtx.cor1[lower.tri(mtx.cor1)] <- 0 # Also zero out one matrix triangle, to avoid duplicate pairs
mtx.maxMin <- melt(mtx.cor1) # Convert the matrix into tidy data
mtx.maxMin <- mtx.maxMin[order(mtx.maxMin$value, decreasing=T), ] # Reorder the data by maxMin correlation
mtx.maxMin <- mtx.maxMin[mtx.maxMin$value != 0, ]
row.names(mtx.maxMin) <- NULL
colnames(mtx.maxMin) <- c("Disease 1", "Disease 2", "Corr. coefficient")
pander(head(mtx.maxMin, n=10))
write.table(mtx.maxMin, fn_maxmin, sep="\t", quote=F,  row.names=F)
mtx.maxMin.tfbs <- data.frame(coef=mtx.maxMin[, 3]) # Save the data for future plotting
mtx.maxMin.tfbs$type <- "tfbs" # Label it
```

The similarity dendrogram can be divided into separate groups:

```{r defineClusters1, echo=FALSE}
par(oma=c(0, 0, 0, 0), mar=c(5.1, 4.1, 4.1,25.1), cex=0.5)
# Plot the dendrogram only, limit y axis. attr(h$colDendrogram, "height") has the maximum height of the dendrogram.
plot(h$colDendrogram, horiz=T) 
# Cut the dentrogram into separate clusters. Tweak the height
abline(v=3) # Visually evaluate the height where to cut
c<-cut(h$colDendrogram, h=3) 
# Check the number of clusters, and the number of members.
for (i in 1:length(c$lower)){
  cat(paste("Cluster", formatC(i, width=2, flag="0"), sep=""), "has", formatC(attr(c$lower[[i]], "members"), width=3), "members", "\n")
  cat(paste(t(labels(c$lower[[i]])), collapse="\n"))
  cat(paste("\n", "\n"))
}
# Output the results into a file
unlink(fn_clust)
for (i in 1:length(c$lower)){ 
  write.table(paste(i, t(labels(c$lower[[i]])), sep="\t"), fn_clust, sep="\t", quote=F,  col.names=F, row.names=F, append=T)
}
```

The "Enrichment 1/2" columns show the average p-values of the group-specific SNPs-regulatory associations. A "-" sign indicates that an association is underrepresented. The "p-value" column shows whether the difference in the associations between the groups is statistically significantly different.

```{r defineGroups1, echo=FALSE}
eset.labels<-character() # Empty vector to hold cluster labels
eset.groups<-numeric() # Empty vector to hold cluster groups
# Set the minimum number of members to be considered for the differential analysis
minmembers<-3
for (i in 1:length(c$lower)) { # Go through each cluster
  # If the number of members is more than a minimum number of members
  if (attr(c$lower[[i]], "members") > minmembers) { 
    eset.labels<-append(eset.labels, labels(c$lower[[i]]))
    eset.groups<-append(eset.groups, rep(i, length(labels(c$lower[[i]]))))
  }
}
```

```{r limmaOnClusters1, warning=FALSE}
eset<-new("ExpressionSet", exprs=as.matrix(mtx[, eset.labels]))
# Make model matrix
design<-model.matrix(~ 0+factor(eset.groups)) 
colnames(design)<-paste("c", unique(eset.groups), sep="")
# Create an empty square matrix to hold counts of DEGs
degs.matrix<-matrix(0, length(c$lower), length(c$lower))
colnames(degs.matrix)<-paste("c", seq(1,length(c$lower)), sep="")
rownames(degs.matrix)<-paste("c", seq(1, length(c$lower)), sep="") 
unlink(fn_degs)
for(i in colnames(design)){ 
  for(j in colnames(design)){
    # Test only unique pairs of clusters
    if (as.numeric(sub("c", "", i)) < as.numeric(sub("c", "", j))) {
      # Contrasts between two clusters
      contrast.matrix<-makeContrasts(contrasts=paste(i, j, sep="-"), levels=design)
      fit <- lmFit(eset, design) 
      fit2 <- contrasts.fit(fit, contrast.matrix)
      fit2 <- eBayes(fit2)
      degs<-topTable(fit2, number=dim(exprs(eset))[[1]], adjust.method="BH") # , p.value=cutoff.pval, lfc=cutoff.lfc)
      if(nrow(degs)>0) {
        # Average values in clusters i and j
        i.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", i))], nrow=nrow(degs)))
        j.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", j))], nrow=nrow(degs)))
        # Merge and convert the values
        degs.pvals.log <- cbind(i.av, j.av)
        degs.pvals <- matrix(0, nrow=nrow(degs.pvals.log), ncol=ncol(degs.pvals.log), dimnames=list(rownames(degs.pvals.log), c(i, j))) # Empty matrix to hold converted p
        for (ii in 1:nrow(degs.pvals.log)) {
          for (jj in 1:ncol(degs.pvals.log)) {
            if (degs.pvals.log[ii, jj] < 0) {sign = -1} else {sign = 1}
            degs.pvals[ii, jj] <- sign/10^abs(degs.pvals.log[ii, jj])
          }
        }
        degs <- cbind(degs, degs.pvals) # Bind the differences p-values with the converted averaged association p-values
        degs <- degs[ degs$adj.P.Val < 0.1 & (abs(degs[, 7]) < 0.01 | abs(degs[, 8]) < 0.01), ] # Filter non-significant differences. Warning: Hardcoded thresholds
        if(dim(degs)[[1]] > 0) {
          ndegs <- nrow(degs) # The number of differentially associated regulatory datasets
          degs <- degs[order(degs$adj.P.Val, decreasing=F), ] # Order them by the ratio of the differences
          print(paste(i, "vs.", j, ", number of degs significant at adj.p.val<0.5:", ndegs))
          # Keep the number of DEGs in the matrix
          degs.matrix[as.numeric(sub("c", "", i)), as.numeric(sub("c", "", j))] <- ndegs
          degs.table <- merge(degs, trackDb.hg19, by="row.names", all.x=TRUE, sort=FALSE) # Merge with the descriptions
          if(ndegs > 10) { ndegs <- 10 }
          pander(degs.table[1:ndegs, c(1, 8, 9, 6, 10)])
          write.table(degs.table[, c(1, 8, 9, 6, 10)], fn_degs, sep="\t", quote=F,  col.names=NA, append=T)
        }
      }
    } 
  }
}
print("Counts of regulatory elements differentially associated with each group")
pander(degs.matrix)
```

**Text mining question 2:** Are the terms associated stronger with the diseases in one vs. the other cluster based on the literature strength? Are the terms themselves related based on the literature? *Expected answer:* Yes, the literature associations should confirm the relationships.

Summary
---
1. There are 4 clusters. The first cluster drives all the differences.

|    | C1 | C2                                                      | C3                                                       | C4                                                       |
|----|----|---------------------------------------------------------|----------------------------------------------------------|----------------------------------------------------------|
| C1 |    | Cell types: Gm12878 Reg: NFkB, Pol2, MTA3, NFIC, NFATC1 | Cell types: Gm12878  Reg: NFkB, Pol2, MTA3, NFIC, NFATC1 | Cell types: Gm12878  Reg: NFkB, Pol2, MTA3, NFIC, NFATC1 |
| C2 |    |                                                         | Nothing significant                                      | Nothing significant                                      |
| C3 |    |                                                         |                                                          | Nothing significant                                      |
| C4 |    |                                                         |                                                          |                                                          |

Analysis of histone marks
===
Out of all regulatory datasets, we select only histone marks

```{r loadData2, echo=FALSE}
# Define output and data subfolders to use, change to analyze different data
rname<-"results//" # Output folder
# One or more GenomeRunner Web results data folders.
dname <- "data.gr//ENCODE_FDR/"
mtx<-do.call("rbind", lapply(dname, function(fn) as.matrix(read.table(paste(fn, "matrix.txt", sep=""), sep="\t", header=T, row.names=1))))
mtx <- mtx[grep("histone", rownames(mtx), ignore.case=T), ] # Limit the GFs to TFBSs and Histone marks
# Exploratory: check quantiles and remove diseaases showing no enrichments
# mtx.sumstat <- as.data.frame(apply(mtx, 2, quantile)) # Get quantiles
# mtx <- mtx[ , apply(mtx.sumstat, 2, function(x) sum(abs(x)) != 5)] # REmove those that have all "1" or "-1"
# Optional: filter unused genomic features
# mtx<-mtx[grep("snp", rownames(mtx), ignore.case=T, invert=T), ]
mtx<-mtx.transform(mtx) # -log10 transform p-values
# Optional: adjust columns for multiple testing. See utils.R for the function definition.
# mtx<-mtx.adjust(mtx) 
trackDb.hg19 <- read.table("data.gr//gf_descriptions.hg19.txt", sep="\t", row.names=1)
fn_maxmin <- "results//maxmin_correlations_histone.txt"
fn_clust <- "results/clustering_histone.txt"
fn_degs <- "results/clusters-degs_histone.txt"
```

```{r preprocessData2, echo=FALSE}
dim(mtx) # Check original dimensions
# Define minimum number of times a row/col should have values above the cutoffs
numofsig<-1
cutoff<- -log10(0.1) # q-value significance cutoff
# What remains if we remove rows/cols with nothing significant
dim(mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ])
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig])
# Trim the matrix
mtx<-mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ]
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig]
```

```{r preprocessCorrel2, echo=FALSE}
# rcorr returns a list, [[1]] - correl coeffs, [[3]] - p-values. Type - pearson/spearman
mtx.cor<-rcorr(as.matrix(mtx), type="spearman")
# Optionally, try kendall correlation
# mtx.cor[[1]]<-cor(as.matrix(mtx), method="kendall")
```

We check how regulatory similarity correlates with overlap similarity.

```{r RegOverlapCorrel2}
mtx.cor.melt <- melt(mtx.cor[[1]]) # Convert correlation matrix to long format
b <- mtx.cor.melt[!(mtx.cor.melt[, 1] == mtx.cor.melt[, 2]), , drop=F] # Exclude self-self associations
# rownames(b) <- paste(b[, 1], b[, 2], sep="-") # Make names like term1-term2
# b <- b[, 3, drop=F] # Keep only REGULATORY counts
# c <- merge(a, b, by="row.names") # Combine OVERLAP and REGULATORY counts
c <- left_join(a, b, by = c("V1" = "Var1", "V2" = "Var2"))
(rcorr(c[, 3], c[, 4])) # Finally, correlation between the two
```

Next, we visualize heatmap of regulatory similarity. 

```{r epigenomicVisualization2, echo=FALSE}
par(oma=c(5,0,0,5), mar=c(10, 4.1, 4.1, 5)) # Adjust margins
color<-colorRampPalette(c("blue","yellow")) # Define color gradient
#color<-greenred #Standard green-black-red palette
# Adjust clustering parameters.
# Distance: "euclidean", "maximum","manhattan" or "minkowski". Do not use "canberra" or "binary"
# Clustering: "ward", "single", "complete", "average", "mcquitty", "median" or "centroid"
dist.method<-"euclidean"  
hclust.method<-"ward.D2"
# Setting breaks to go from minimum to maximum correlation coefficients,
# excluding min/max outliers. This way we get rid of diagonale of 1's
granularity = 10
my.breaks <- seq(min(mtx.cor[[1]][mtx.cor[[1]]!=min(mtx.cor[[1]])]),
                 max(mtx.cor[[1]][mtx.cor[[1]]!=max(mtx.cor[[1]])]),
                 length.out=(2*granularity + 1))
h<-heatmap.2(as.matrix(mtx.cor[[1]]), trace="none", density.info="none", col=color, distfun=function(x){dist(x, method=dist.method)}, hclustfun=function(x){hclust(x, method=hclust.method)}, cexRow=0.7, cexCol=0.7, breaks=my.breaks)
```

**Text mining question 1:** Are the diseases within a cluster share stronger literature similarity than the diseases between the clusters? To answer, we need literature similarity scores for each pair, then split the pairs into cluster-specific groups and compare score distributions with what can be expected by chance, calculating the p-values for it. *Expected answer:* Diseases within each cluster are related to each other by literature findings stronger than could be expected by chance. Diseases between the clusters are not related to each other by literature findings, and this also may be statistically significant.

The top 10 pairs of autoimmune-associated SNPs are most similar with each other.

```{r maxMin2, echo=FALSE}
# Checking max/min correlations
mtx.cor1<-mtx.cor[[1]]
diag(mtx.cor1)<-0 # We don't need to consider self correlations, zero them out
mtx.cor1[lower.tri(mtx.cor1)] <- 0 # Also zero out one matrix triangle, to avoid duplicate pairs
mtx.maxMin <- melt(mtx.cor1) # Convert the matrix into tidy data
mtx.maxMin <- mtx.maxMin[order(mtx.maxMin$value, decreasing=T), ] # Reorder the data by maxMin correlation
mtx.maxMin <- mtx.maxMin[mtx.maxMin$value != 0, ]
row.names(mtx.maxMin) <- NULL
colnames(mtx.maxMin) <- c("Disease 1", "Disease 2", "Corr. coefficient")
pander(head(mtx.maxMin, n=10))
write.table(mtx.maxMin, fn_maxmin, sep="\t", quote=F,  row.names=F)
mtx.maxMin.histone <- data.frame(coef=mtx.maxMin[, 3]) # Save the data for future plotting
mtx.maxMin.histone$type <- "histone" # Label it
```

The similarity dendrogram can be divided into separate groups:

```{r defineClusters2, echo=FALSE}
par(oma=c(0, 0, 0, 0), mar=c(5.1, 4.1, 4.1,25.1), cex=0.5)
# Plot the dendrogram only, limit y axis. attr(h$colDendrogram, "height") has the maximum height of the dendrogram.
plot(h$colDendrogram, horiz=T) 
# Cut the dentrogram into separate clusters. Tweak the height
abline(v=2.8) # Visually evaluate the height where to cut
c<-cut(h$colDendrogram, h=2.8) 
# Check the number of clusters, and the number of members.
for (i in 1:length(c$lower)){
  cat(paste("Cluster", formatC(i, width=2, flag="0"), sep=""), "has", formatC(attr(c$lower[[i]], "members"), width=3), "members", "\n")
  cat(paste(t(labels(c$lower[[i]])), collapse="\n"))
  cat(paste("\n", "\n"))
}
# Output the results into a file
unlink(fn_clust)
for (i in 1:length(c$lower)){ 
  write.table(paste(i, t(labels(c$lower[[i]])), sep="\t"), fn_clust, sep="\t", quote=F,  col.names=F, row.names=F, append=T)
}
```

The "Enrichment 1/2" columns show the average p-values of the group-specific SNPs-regulatory associations. A "-" sign indicates that an association is underrepresented. The "p-value" column shows whether the difference in the associations bwtween the groups is statistically significantly different.

```{r defineGroups2, echo=FALSE}
eset.labels<-character() # Empty vector to hold cluster labels
eset.groups<-numeric() # Empty vector to hold cluster groups
# Set the minimum number of members to be considered for the differential analysis
minmembers<-3
for (i in 1:length(c$lower)) { # Go through each cluster
  # If the number of members is more than a minimum number of members
  if (attr(c$lower[[i]], "members") > minmembers) { 
    eset.labels<-append(eset.labels, labels(c$lower[[i]]))
    eset.groups<-append(eset.groups, rep(i, length(labels(c$lower[[i]]))))
  }
}
```

```{r limmaOnClusters2, warning=FALSE}
eset<-new("ExpressionSet", exprs=as.matrix(mtx[, eset.labels]))
# Make model matrix
design<-model.matrix(~ 0+factor(eset.groups)) 
colnames(design)<-paste("c", unique(eset.groups), sep="")
# Create an empty square matrix to hold counts of DEGs
degs.matrix<-matrix(0, length(c$lower), length(c$lower))
colnames(degs.matrix)<-paste("c", seq(1,length(c$lower)), sep="")
rownames(degs.matrix)<-paste("c", seq(1, length(c$lower)), sep="") 
unlink(fn_degs)
for(i in colnames(design)){ 
  for(j in colnames(design)){
    # Test only unique pairs of clusters
    if (as.numeric(sub("c", "", i)) < as.numeric(sub("c", "", j))) {
      # Contrasts between two clusters
      contrast.matrix<-makeContrasts(contrasts=paste(i, j, sep="-"), levels=design)
      fit <- lmFit(eset, design) 
      fit2 <- contrasts.fit(fit, contrast.matrix)
      fit2 <- eBayes(fit2)
      degs<-topTable(fit2, number=dim(exprs(eset))[[1]], adjust.method="BH") # , p.value=cutoff.pval, lfc=cutoff.lfc)
      if(nrow(degs)>0) {
        # Average values in clusters i and j
        i.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", i))], nrow=nrow(degs)))
        j.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", j))], nrow=nrow(degs)))
        # Merge and convert the values
        degs.pvals.log <- cbind(i.av, j.av)
        degs.pvals <- matrix(0, nrow=nrow(degs.pvals.log), ncol=ncol(degs.pvals.log), dimnames=list(rownames(degs.pvals.log), c(i, j))) # Empty matrix to hold converted p
        for (ii in 1:nrow(degs.pvals.log)) {
          for (jj in 1:ncol(degs.pvals.log)) {
            if (degs.pvals.log[ii, jj] < 0) {sign = -1} else {sign = 1}
            degs.pvals[ii, jj] <- sign/10^abs(degs.pvals.log[ii, jj])
          }
        }
        degs <- cbind(degs, degs.pvals) # Bind the differences p-values with the converted averaged association p-values
        degs <- degs[ degs$adj.P.Val < 0.1 & (abs(degs[, 7]) < 0.01 | abs(degs[, 8]) < 0.01), ] # Filter non-significant differences. Warning: Hardcoded thresholds
        if(dim(degs)[[1]] > 0) {
          ndegs <- nrow(degs) # The number of differentially associated regulatory datasets
          degs <- degs[order(degs$adj.P.Val, decreasing=F), ] # Order them by the ratio of the differences
          print(paste(i, "vs.", j, ", number of degs significant at adj.p.val<0.5:", ndegs))
          # Keep the number of DEGs in the matrix
          degs.matrix[as.numeric(sub("c", "", i)), as.numeric(sub("c", "", j))] <- ndegs
          degs.table <- merge(degs, trackDb.hg19, by="row.names", all.x=TRUE, sort=FALSE) # Merge with the descriptions
          if(ndegs > 10) { ndegs <- 10 }
          pander(degs.table[1:ndegs, c(1, 8, 9, 6, 10)])
          write.table(degs.table[, c(1, 8, 9, 6, 10)], fn_degs, sep="\t", quote=F,  col.names=NA, append=T)
        }
      }
    } 
  }
}
print("Counts of regulatory elements differentially associated with each group")
pander(degs.matrix)
```

**Text mining question 2:** Are the terms associated stronger with the diseases in one vs. the other cluster based on the literature strength? Are the terms themselves related based on the literature? *Expected answer:* Yes, the literature associations should confirm the relationships.

Summary
---

1. Again, cluster 1 is strongly distinct. Cluster 2 is less so. Histone marks seem all active.

|    | C1 | C2                                                                                | C3                                                                                | C4                                                                                |
|----|----|-----------------------------------------------------------------------------------|-----------------------------------------------------------------------------------|-----------------------------------------------------------------------------------|
| C1 |    | Cell types: Gm12878, CD20+  Reg: H3K4me1, H3K9me3, H3K9ac, H3K27ac, H2az, H3K4me2 | Cell types: Gm12878, CD20+  Reg: H3K4me1, H3K9me3, H3K9ac, H3K27ac, H2az, H3K4me2 | Cell types: Gm12878, CD20+  Reg: H3K4me1, H3K9me3, H3K9ac, H3K27ac, H2az, H3K4me2 |
| C2 |    |                                                                                   | Cell types: K562, NHEK, NHDF-Ad, NH-A, HMEC  Reg: H3K36me3, H4K20me1, H3K79me2    | Nothing significant                                                               |
| C3 |    |                                                                                   |                                                                                   | Nothing significant                                                               |
| C4 |    |                                                                                   |                                                                                   |                                                                                   |

Analysis of all regulatory datasets
===
Out of all regulatory datasets, we select all. The goal here is to get potentially tighter clustering.

```{r loadData3, echo=FALSE}
# Define output and data subfolders to use, change to analyze different data
rname<-"results//" # Output folder
# One or more GenomeRunner Web results data folders.
dname <- "data.gr//ENCODE_FDR/"
mtx<-do.call("rbind", lapply(dname, function(fn) as.matrix(read.table(paste(fn, "matrix.txt", sep=""), sep="\t", header=T, row.names=1))))
# mtx <- mtx[grep("histone", rownames(mtx), ignore.case=T), ] # Limit the GFs to TFBSs and Histone marks
# Exploratory: check quantiles and remove diseaases showing no enrichments
# mtx.sumstat <- as.data.frame(apply(mtx, 2, quantile)) # Get quantiles
# mtx <- mtx[ , apply(mtx.sumstat, 2, function(x) sum(abs(x)) != 5)] # REmove those that have all "1" or "-1"
# Optional: filter unused genomic features
# mtx<-mtx[grep("snp", rownames(mtx), ignore.case=T, invert=T), ]
mtx<-mtx.transform(mtx) # -log10 transform p-values
# Optional: adjust columns for multiple testing. See utils.R for the function definition.
# mtx<-mtx.adjust(mtx) 
trackDb.hg19 <- read.table("data.gr//gf_descriptions.hg19.txt", sep="\t", row.names=1)
fn_maxmin <- "results//maxmin_correlations_all.txt"
fn_clust <- "results/clustering_all.txt"
fn_degs <- "results/clusters-degs_all.txt"
```

```{r preprocessData3, echo=FALSE}
dim(mtx) # Check original dimensions
# Define minimum number of times a row/col should have values above the cutoffs
numofsig<-1
cutoff<- -log10(0.1) # q-value significance cutoff
# What remains if we remove rows/cols with nothing significant
dim(mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ])
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig])
# Trim the matrix
mtx<-mtx[apply(mtx, 1, function(x) sum(abs(x) > cutoff)) >= numofsig, ]
        # apply(mtx, 2, function(x) sum(abs(x)>cutoff))>=numofsig]
```

```{r preprocessCorrel3, echo=FALSE}
# rcorr returns a list, [[1]] - correl coeffs, [[3]] - p-values. Type - pearson/spearman
mtx.cor<-rcorr(as.matrix(mtx), type="spearman")
# Optionally, try kendall correlation
# mtx.cor[[1]]<-cor(as.matrix(mtx), method="kendall")
```

We check how regulatory similarity correlates with overlap similarity.

```{r RegOverlapCorrel3}
mtx.cor.melt <- melt(mtx.cor[[1]]) # Convert correlation matrix to long format
b <- mtx.cor.melt[!(mtx.cor.melt[, 1] == mtx.cor.melt[, 2]), , drop=F] # Exclude self-self associations
# rownames(b) <- paste(b[, 1], b[, 2], sep="-") # Make names like term1-term2
# b <- b[, 3, drop=F] # Keep only REGULATORY counts
# c <- merge(a, b, by="row.names") # Combine OVERLAP and REGULATORY counts
c <- left_join(a, b, by = c("V1" = "Var1", "V2" = "Var2"))
(rcorr(c[, 3], c[, 4])) # Finally, correlation between the two
```

Next, we visualize heatmap of regulatory similarity. 

```{r epigenomicVisualization3, echo=FALSE}
par(oma=c(5,0,0,5), mar=c(10, 4.1, 4.1, 5)) # Adjust margins
color<-colorRampPalette(c("blue","yellow")) # Define color gradient
#color<-greenred #Standard green-black-red palette
# Adjust clustering parameters.
# Distance: "euclidean", "maximum","manhattan" or "minkowski". Do not use "canberra" or "binary"
# Clustering: "ward", "single", "complete", "average", "mcquitty", "median" or "centroid"
dist.method<-"euclidean"  
hclust.method<-"ward.D2"
# Setting breaks to go from minimum to maximum correlation coefficients,
# excluding min/max outliers. This way we get rid of diagonale of 1's
granularity = 10
my.breaks <- seq(min(mtx.cor[[1]][mtx.cor[[1]]!=min(mtx.cor[[1]])]),
                 max(mtx.cor[[1]][mtx.cor[[1]]!=max(mtx.cor[[1]])]),
                 length.out=(2*granularity + 1))
h<-heatmap.2(as.matrix(mtx.cor[[1]]), trace="none", density.info="none", col=color, distfun=function(x){dist(x, method=dist.method)}, hclustfun=function(x){hclust(x, method=hclust.method)}, cexRow=0.7, cexCol=0.7, breaks=my.breaks)
```

The top 10 pairs of disease-associated SNPs are most similar with each other.

```{r maxMin3, echo=FALSE}
# Checking max/min correlations
mtx.cor1<-mtx.cor[[1]]
diag(mtx.cor1)<-0 # We don't need to consider self correlations, zero them out
mtx.cor1[lower.tri(mtx.cor1)] <- 0 # Also zero out one matrix triangle, to avoid duplicate pairs
mtx.maxMin <- melt(mtx.cor1) # Convert the matrix into tidy data
mtx.maxMin <- mtx.maxMin[order(mtx.maxMin$value, decreasing=T), ] # Reorder the data by maxMin correlation
mtx.maxMin <- mtx.maxMin[mtx.maxMin$value != 0, ]
row.names(mtx.maxMin) <- NULL
colnames(mtx.maxMin) <- c("Disease 1", "Disease 2", "Corr. coefficient")
pander(head(mtx.maxMin, n=10))
write.table(mtx.maxMin, fn_maxmin, sep="\t", quote=F,  row.names=F)
mtx.maxMin.all <- data.frame(coef=mtx.maxMin[, 3]) # Save the data for future plotting
mtx.maxMin.all$type <- "all" # Label it
```

The similarity dendrogram can be divided into separate groups:

```{r defineClusters3, echo=FALSE}
par(oma=c(0, 0, 0, 0), mar=c(5.1, 4.1, 4.1,25.1), cex=0.5)
# Plot the dendrogram only, limit y axis. attr(h$colDendrogram, "height") has the maximum height of the dendrogram.
plot(h$colDendrogram, horiz=T) 
# Cut the dentrogram into separate clusters. Tweak the height
abline(v=2.55) # Visually evaluate the height where to cut
c<-cut(h$colDendrogram, h=2.55) 
# Check the number of clusters, and the number of members.
for (i in 1:length(c$lower)){
  cat(paste("Cluster", formatC(i, width=2, flag="0"), sep=""), "has", formatC(attr(c$lower[[i]], "members"), width=3), "members", "\n")
  cat(paste(t(labels(c$lower[[i]])), collapse="\n"))
  cat(paste("\n", "\n"))
}
# Output the results into a file
unlink(fn_clust)
for (i in 1:length(c$lower)){ 
  write.table(paste(i, t(labels(c$lower[[i]])), sep="\t"), fn_clust, sep="\t", quote=F,  col.names=F, row.names=F, append=T)
}
```

The "Enrichment 1/2" columns show the average p-values of the group-specific SNPs-regulatory associations. A "-" sign indicates that an association is underrepresented. The "p-value" column shows whether the difference in the associations bwtween the groups is statistically significantly different.

```{r defineGroups3, echo=FALSE}
eset.labels<-character() # Empty vector to hold cluster labels
eset.groups<-numeric() # Empty vector to hold cluster groups
# Set the minimum number of members to be considered for the differential analysis
minmembers<-3
for (i in 1:length(c$lower)) { # Go through each cluster
  # If the number of members is more than a minimum number of members
  if (attr(c$lower[[i]], "members") > minmembers) { 
    eset.labels<-append(eset.labels, labels(c$lower[[i]]))
    eset.groups<-append(eset.groups, rep(i, length(labels(c$lower[[i]]))))
  }
}
```

```{r limmaOnClusters3, warning=FALSE}
eset<-new("ExpressionSet", exprs=as.matrix(mtx[, eset.labels]))
# Make model matrix
design<-model.matrix(~ 0+factor(eset.groups)) 
colnames(design)<-paste("c", unique(eset.groups), sep="")
# Create an empty square matrix to hold counts of DEGs
degs.matrix<-matrix(0, length(c$lower), length(c$lower))
colnames(degs.matrix)<-paste("c", seq(1,length(c$lower)), sep="")
rownames(degs.matrix)<-paste("c", seq(1, length(c$lower)), sep="") 
unlink(fn_degs)
for(i in colnames(design)){ 
  for(j in colnames(design)){
    # Test only unique pairs of clusters
    if (as.numeric(sub("c", "", i)) < as.numeric(sub("c", "", j))) {
      # Contrasts between two clusters
      contrast.matrix<-makeContrasts(contrasts=paste(i, j, sep="-"), levels=design)
      fit <- lmFit(eset, design) 
      fit2 <- contrasts.fit(fit, contrast.matrix)
      fit2 <- eBayes(fit2)
      degs<-topTable(fit2, number=dim(exprs(eset))[[1]], adjust.method="BH") # , p.value=cutoff.pval, lfc=cutoff.lfc)
      if(nrow(degs)>0) {
        # Average values in clusters i and j
        i.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", i))], nrow=nrow(degs)))
        j.av<-rowMeans(matrix(exprs(eset)[rownames(degs), eset.groups == as.numeric(sub("c", "", j))], nrow=nrow(degs)))
        # Merge and convert the values
        degs.pvals.log <- cbind(i.av, j.av)
        degs.pvals <- matrix(0, nrow=nrow(degs.pvals.log), ncol=ncol(degs.pvals.log), dimnames=list(rownames(degs.pvals.log), c(i, j))) # Empty matrix to hold converted p
        for (ii in 1:nrow(degs.pvals.log)) {
          for (jj in 1:ncol(degs.pvals.log)) {
            if (degs.pvals.log[ii, jj] < 0) {sign = -1} else {sign = 1}
            degs.pvals[ii, jj] <- sign/10^abs(degs.pvals.log[ii, jj])
          }
        }
        degs <- cbind(degs, degs.pvals) # Bind the differences p-values with the converted averaged association p-values
        degs <- degs[ degs$adj.P.Val < 0.1 & (abs(degs[, 7]) < 0.01 | abs(degs[, 8]) < 0.01), ] # Filter non-significant differences. Warning: Hardcoded thresholds
        if(dim(degs)[[1]] > 0) {
          ndegs <- nrow(degs) # The number of differentially associated regulatory datasets
          degs <- degs[order(degs$adj.P.Val, decreasing=F), ] # Order them by the ratio of the differences
          print(paste(i, "vs.", j, ", number of degs significant at adj.p.val<0.5:", ndegs))
          # Keep the number of DEGs in the matrix
          degs.matrix[as.numeric(sub("c", "", i)), as.numeric(sub("c", "", j))] <- ndegs
          degs.table <- merge(degs, trackDb.hg19, by="row.names", all.x=TRUE, sort=FALSE) # Merge with the descriptions
          if(ndegs > 10) { ndegs <- 10 }
          pander(degs.table[1:ndegs, c(1, 8, 9, 6, 10)])
          write.table(degs.table[, c(1, 8, 9, 6, 10)], fn_degs, sep="\t", quote=F,  col.names=NA, append=T)
        }
      }
    } 
  }
}
print("Counts of regulatory elements differentially associated with each group")
pander(degs.matrix)
```

Summary
---
The picture is not as good as when we are taking subsets of regulatory datasets.

|                                                                                                                                                                                                                                                                                                                                                                                                                                                      | c1 | c2                                                                                                               | c3                                                                 | c4                                                                                                       |
|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----|------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
| ##   Cluster01 has  14 members      ## Platelet_counts     ## Liver_enzyme_levels_gamma_glutamyl_transferase     ## Red_blood_cell_traits     ## LDL_cholesterol     ## HDL_cholesterol     ## Triglycerides     ## Type_2_diabetes     ## Fasting_glucose_related_traits     ## Bone_mineral_density     ## Alzheimers_combined     ## Creatinine_levels     ## Renal_function_related_traits_BUN     ## Urate_levels     ## Chronic_kidney_disease |    | 416 total up in C2     Cell types: Gm*, B cells     Factors: NFIC, FOXM1, RUNX3, CEBPB and other TFBSs; DNAse HS | 1 total up in C3     Cell types: Monocytes CD14+     Factors: CTCF |                                                                                                          |
| ##   Multiple_sclerosis     ## Kawasaki_disease     ## Celiac_disease     ## Systemic_lupus_erythematosus     ## Psoriasis     ## Ulcerative_colitis     ## Rheumatoid_arthritis     ## Crohns_disease     ## Autoimmune_thyroiditis                                                                                                                                                                                                                 |    |                                                                                                                  |                                                                    | 96 total up in C2     Cell types: B cells, Gm*     Factors: RUNX3, NFIC, FOXM1 and other TFBSs, DNAse HS |
| ##   Primary_biliary_cirrhosis     ## Ankylosing_spondylitis     ## Systemic_sclerosis     ## Migraine     ## Primary_sclerosing_cholangitis                                                                                                                                                                                                                                                                                                         |    |                                                                                                                  |                                                                    | 1 total up in C3     Cell types: Monocytes CD14+     Factors: CTCF                                       |
| ##   Juvenile_idiopathic_arthritis     ## Atopic_dermatitis     ## Alopecia_areata     ## C_reactive_protein     ## Allergy     ## Type_1_diabetes     ## Vitiligo     ## Behcets_disease     ## Progressive_supranuclear_palsy     ## Restless_legs_syndrome     ## Asthma                                                                                                                                                                          |    |                                                                                                                  |                                                                    |                                                                                                          |

Distribution of maxMin correlation coefficients
---
```{r maxMinHist}
maxmin <- rbind(mtx.maxMin.tfbs, mtx.maxMin.histone, mtx.maxMin.all)
ggplot(maxmin, aes(coef, fill=type)) + geom_density(alpha=0.2)
```

Regulatory- and co-morbidity similarities
-------------------------------------------

To evaluate whether regulatory and co-morbidity measurements correlate, a matrix of disease-disease co-morbidity correlations ([AllNet3.txt](http://barabasilab.neu.edu/projects/hudine/resource/datasets/AllNet3.net)) is downloaded.

```{r diseaseNetwork, echo=FALSE}
# All disease-disease relationships
mtx.disease <- read.table("../../AllNet3.net", sep="\t", header=F)
# Mapping of term IDs to ICD9 codes
term.mapping <- read.table("data/icd9_mapping.txt", sep="\t", header=F, row.names=1)
colnames(term.mapping) <- "ICD9"
# Sanity check, is there differences in disease codes? Should be 0
# setdiff(unique(term.mapping$ICD9), unique(mtx.disease$V1))
```

We create square matrixes (14x14) of disease-disease co-morbitity correlations and regulatory correlations.

```{r diseaseNetwork1, echo=FALSE}
# Create empty matrix of term disease-disease relationships ($V5 - co-occurrence)
term.ICD9.occur <- matrix(0, nrow=nrow(term.mapping), ncol=nrow(term.mapping))
rownames(term.ICD9.occur) <- rownames(term.mapping)
colnames(term.ICD9.occur) <- rownames(term.mapping)
# Create two others, to hold relative risk ($V6) and phi-correlation ($V9)
term.ICD9.risk <- term.ICD9.occur; term.ICD9.phi <- term.ICD9.occur
# Populate this matrix with Barabasi relationship values
for (i in 1:nrow(term.mapping)) {
  for (j in 1:nrow(term.mapping)) {
    # The disease associations matrix is not symmetrical - we pull up the index with either disease1-disease2 relationship, or disease2-disease1 relationship
    idx <- (mtx.disease$V1 == term.mapping$ICD9[i] & mtx.disease$V2 == term.mapping$ICD9[j]) | (mtx.disease$V2 == term.mapping$ICD9[i] & mtx.disease$V1 == term.mapping$ICD9[j])
    # If relationship pair is found, store it. Self-self relationships will be 0
    if (sum(idx) == 1) { 
    term.ICD9.occur[i, j] <- mtx.disease$V5[idx]
    term.ICD9.risk[i, j] <- mtx.disease$V6[idx]
    term.ICD9.phi[i, j] <- mtx.disease$V9[idx]  
    }
  }
  # For each row, replace self-self associations (zeros) by row maximum
  term.ICD9.occur[i, term.ICD9.occur[i, ] == 0] <- max(term.ICD9.occur[i, ]) + 0.01
  term.ICD9.risk[i, term.ICD9.risk[i, ] == 0] <- max(term.ICD9.risk[i, ]) + 0.01
  term.ICD9.phi[i, term.ICD9.phi[i, ] == 0] <- max(term.ICD9.phi[i, ]) + 0.01
}
```

To evaluate correlation between the two methods of measurements, the matrixes are correlated with each other. A matrix of correlation coefficients, a total number of pairs used for correlation measurement, and a matrix of p-values are outputted.

The ongoing debate is whether to remove or keep self-self associations.

```{r diseaseNetwork3, echo=FALSE}
# Finally, check correlation between pairwise relationships
print("Co-occurrence")
term.ICD9.occur.melt <- melt(term.ICD9.occur)
term.cor.occur <- left_join(mtx.cor.melt, term.ICD9.occur.melt, by=c("Var1" = "Var1", "Var2" = "Var2"))
#term.cor.occur <- term.cor.occur[ term.cor.occur$Var1 != term.cor.occur$Var2, ]
(rcorr(term.cor.occur$value.x, term.cor.occur$value.y))
print("Relative risk")
term.ICD9.risk.melt <- melt(term.ICD9.risk)
term.cor.risk <- left_join(mtx.cor.melt, term.ICD9.risk.melt, by=c("Var1" = "Var1", "Var2" = "Var2"))
#term.cor.risk <- term.cor.risk[ term.cor.risk$Var1 != term.cor.risk$Var2, ]
(rcorr(term.cor.risk$value.x, term.cor.risk$value.y))
print("Phi-correlation")
term.ICD9.phi.melt <- melt(term.ICD9.phi)
term.cor.phi <- left_join(mtx.cor.melt, term.ICD9.phi.melt, by=c("Var1" = "Var1", "Var2" = "Var2"))
#term.cor.phi <- term.cor.phi[ term.cor.phi$Var1 != term.cor.phi$Var2, ]
(rcorr(term.cor.phi$value.x, term.cor.phi$value.y))

```

The regulatory and co-morbidity-based (Phi-correlations) disease-disease correlations correlate with each other at Pearson's correlation coefficient of 0.54 (when keeping self-correlations, p-value = 0). Using "relative risk" co-morbidity correlations produces similar results.



